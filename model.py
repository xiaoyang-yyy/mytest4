import pandas as pd
import numpy as np
import os
import joblib  # æ›¿æ¢pickleï¼Œæ›´é€‚åˆsklearnæ¨¡å‹ä¸”å‹ç¼©æ•ˆæœæ›´å¥½
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier

# ===================== åŸºç¡€é…ç½®ä¸ç›®å½•æ£€æŸ¥ =====================
# å®šä¹‰è·¯å¾„ï¼ˆrå‰ç¼€é¿å…è½¬ä¹‰ï¼‰
file_path = r"D:\streamlit_env\student_data_adjusted_rounded.csv"
model_dir = r"D:\streamlit_env"

# æ£€æŸ¥å¹¶åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
if not os.path.exists(model_dir):
    os.makedirs(model_dir)
    print(f"ğŸ“ ç›®å½•ä¸å­˜åœ¨ï¼Œå·²åˆ›å»ºï¼š{model_dir}")
else:
    print(f"ğŸ“ ç›®å½•å·²å­˜åœ¨ï¼š{model_dir}")

# ===================== 1. åŠ è½½å¹¶æ ¡éªŒæ•°æ® =====================
try:
    # å…¼å®¹ä¸åŒç¼–ç çš„CSVæ–‡ä»¶
    try:
        df = pd.read_csv(file_path, encoding='gbk')
    except:
        df = pd.read_csv(file_path, encoding='utf-8')
    
    # æ¸…ç†åˆ—å
    df.columns = (
        df.columns
        .str.strip()
        .str.replace('ï¼ˆå°æ—¶ï¼‰', '', regex=False)
        .str.replace('ï¼ˆ', '(', regex=False)
        .str.replace('ï¼‰', ')', regex=False)
    )
    
    # æ ¡éªŒå¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = ['å­¦å·', 'æ€§åˆ«', 'ä¸“ä¸š', 'æ¯å‘¨å­¦ä¹ æ—¶é•¿', 'ä¸Šè¯¾å‡ºå‹¤ç‡', 'æœŸä¸­è€ƒè¯•åˆ†æ•°', 'ä½œä¸šå®Œæˆç‡', 'æœŸæœ«è€ƒè¯•åˆ†æ•°']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼š{missing_cols}")
    
    # æ¸…æ´—æ•°æ®
    df = df[required_cols].dropna()
    numeric_cols = ['æ¯å‘¨å­¦ä¹ æ—¶é•¿', 'ä¸Šè¯¾å‡ºå‹¤ç‡', 'æœŸä¸­è€ƒè¯•åˆ†æ•°', 'ä½œä¸šå®Œæˆç‡', 'æœŸæœ«è€ƒè¯•åˆ†æ•°']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df = df.dropna()
    
    # æ ¡éªŒæ•°æ®é‡ï¼ˆè‡³å°‘10æ¡æ‰èƒ½è®­ç»ƒï¼‰
    if len(df) < 10:
        raise ValueError(f"æœ‰æ•ˆæ•°æ®é‡è¿‡å°‘ï¼Œä»…{len(df)}æ¡ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
    
    print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œæœ‰æ•ˆæ•°æ®é‡ï¼š{len(df)}æ¡")
except Exception as e:
    print(f"âŒ æ•°æ®åŠ è½½/å¤„ç†å¤±è´¥ï¼š{str(e)}")
    exit()

# ===================== 2. è®­ç»ƒæ•°å€¼é¢„æµ‹æ¨¡å‹ï¼ˆçº¿æ€§å›å½’ï¼‰ =====================
try:
    X_reg = df[['æ¯å‘¨å­¦ä¹ æ—¶é•¿', 'ä¸Šè¯¾å‡ºå‹¤ç‡', 'æœŸä¸­è€ƒè¯•åˆ†æ•°', 'ä½œä¸šå®Œæˆç‡']]
    y_reg = df['æœŸæœ«è€ƒè¯•åˆ†æ•°']
    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
        X_reg, y_reg, test_size=0.2, random_state=42
    )
    reg_model = LinearRegression()
    reg_model.fit(X_train_reg, y_train_reg)
    print("âœ… æ•°å€¼é¢„æµ‹æ¨¡å‹è®­ç»ƒæˆåŠŸ")
except Exception as e:
    print(f"âŒ æ•°å€¼æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
    exit()

# ===================== 3. è®­ç»ƒåˆ†ç±»é¢„æµ‹æ¨¡å‹ï¼ˆè½»é‡åŒ–éšæœºæ£®æ—ï¼‰ =====================
try:
    # æ–°å¢æˆç»©ç­‰çº§æ ‡ç­¾ï¼ˆåŠæ ¼/ä¸åŠæ ¼ï¼‰
    df['æˆç»©ç­‰çº§'] = df['æœŸæœ«è€ƒè¯•åˆ†æ•°'].apply(lambda x: 1 if x >= 60 else 0)
    
    # æ ¡éªŒåˆ†ç±»æ ‡ç­¾æ˜¯å¦æœ‰ä¸¤ç§ï¼ˆé¿å…å…¨åŠæ ¼/å…¨ä¸åŠæ ¼ï¼‰
    if df['æˆç»©ç­‰çº§'].nunique() < 2:
        raise ValueError("æˆç»©ç­‰çº§ä»…æœ‰ä¸€ç§ï¼ˆå…¨åŠæ ¼/å…¨ä¸åŠæ ¼ï¼‰ï¼Œæ— æ³•è®­ç»ƒåˆ†ç±»æ¨¡å‹")
    
    # ç‰¹å¾ç¼–ç 
    X_clf = pd.get_dummies(df[['æ€§åˆ«', 'ä¸“ä¸š', 'æ¯å‘¨å­¦ä¹ æ—¶é•¿', 'ä¸Šè¯¾å‡ºå‹¤ç‡', 'æœŸä¸­è€ƒè¯•åˆ†æ•°', 'ä½œä¸šå®Œæˆç‡']])
    y_clf = df['æˆç»©ç­‰çº§']
    X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
        X_clf, y_clf, test_size=0.2, random_state=42
    )
    
    # è½»é‡åŒ–éšæœºæ£®æ—å‚æ•°ï¼ˆæ ¸å¿ƒï¼šå‡å°‘æ ‘æ•°é‡+é™åˆ¶æ ‘æ·±åº¦ï¼Œå¤§å¹…å‡å°ä½“ç§¯ï¼‰
    clf_model = RandomForestClassifier(
        n_estimators=50,       # æ ‘çš„æ•°é‡ä»100å‡åˆ°50ï¼ˆä½“ç§¯å‡åŠï¼‰
        max_depth=10,          # é™åˆ¶æ ‘çš„æ·±åº¦ï¼ˆé¿å…è¿‡æ‹Ÿåˆ+å‡å°ä½“ç§¯ï¼‰
        min_samples_split=5,   # å¢åŠ åˆ†è£‚æœ€å°æ ·æœ¬æ•°ï¼ˆç®€åŒ–æ ‘ç»“æ„ï¼‰
        min_samples_leaf=2,    # å¢åŠ å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
        random_state=42
    )
    clf_model.fit(X_train_clf, y_train_clf)
    print("âœ… åˆ†ç±»é¢„æµ‹æ¨¡å‹ï¼ˆè½»é‡åŒ–ï¼‰è®­ç»ƒæˆåŠŸ")
except Exception as e:
    print(f"âŒ åˆ†ç±»æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼š{str(e)}")
    exit()

# ===================== 4. å‹ç¼©ä¿å­˜æ¨¡å‹ï¼ˆæ ¸å¿ƒï¼šå‡å°æ–‡ä»¶ä½“ç§¯ï¼‰ =====================
try:
    # ä¿å­˜æ•°å€¼é¢„æµ‹æ¨¡å‹ï¼ˆjoblibå‹ç¼©ï¼Œcompress=3å¹³è¡¡å‹ç¼©ç‡å’Œé€Ÿåº¦ï¼‰
    reg_model_path = os.path.join(model_dir, "linear_regression_model.pkl")
    joblib.dump(reg_model, reg_model_path, compress=3)
    print(f"âœ… æ•°å€¼æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{reg_model_path}")
    if os.path.exists(reg_model_path):
        print(f"   âœ”ï¸ æ•°å€¼æ¨¡å‹å¤§å°ï¼š{round(os.path.getsize(reg_model_path)/1024, 2)} KB")
    
    # ä¿å­˜åˆ†ç±»é¢„æµ‹æ¨¡å‹ï¼ˆé«˜å‹ç¼©æ¯”ï¼‰
    clf_model_path = os.path.join(model_dir, "random_forest_clf.pkl")
    joblib.dump(clf_model, clf_model_path, compress=3)  # compress=1~9ï¼Œ3æ˜¯æœ€ä¼˜å¹³è¡¡
    print(f"âœ… åˆ†ç±»æ¨¡å‹å·²ä¿å­˜è‡³ï¼š{clf_model_path}")
    if os.path.exists(clf_model_path):
        print(f"   âœ”ï¸ åˆ†ç±»æ¨¡å‹å¤§å°ï¼š{round(os.path.getsize(clf_model_path)/1024, 2)} KB")
    
    # ä¿å­˜åˆ†ç±»æ¨¡å‹çš„ç‰¹å¾åˆ—åï¼ˆé¢„æµ‹æ—¶å¿…é¡»ï¼‰
    feature_cols_path = os.path.join(model_dir, "clf_feature_cols.pkl")
    joblib.dump(X_clf.columns, feature_cols_path, compress=3)
    print(f"âœ… ç‰¹å¾åˆ—åå·²ä¿å­˜è‡³ï¼š{feature_cols_path}")
    if os.path.exists(feature_cols_path):
        print(f"   âœ”ï¸ ç‰¹å¾åˆ—åæ–‡ä»¶å¤§å°ï¼š{round(os.path.getsize(feature_cols_path)/1024, 2)} KB")

except Exception as e:
    print(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥ï¼š{str(e)}")
    exit()

# ===================== éªŒè¯æ–‡ä»¶ç”Ÿæˆ =====================
print("\nğŸ‰ æ‰€æœ‰æ¨¡å‹ä¿å­˜å®Œæˆï¼")
print("\nğŸ“‹ æ¨¡å‹ç›®å½•ä¸‹çš„.pklæ–‡ä»¶åˆ—è¡¨ï¼š")
for file in os.listdir(model_dir):
    if file.endswith('.pkl'):
        file_size = round(os.path.getsize(os.path.join(model_dir, file))/1024, 2)
        print(f"   - {file} | å¤§å°ï¼š{file_size} KB")
